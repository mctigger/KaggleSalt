{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [00:05<00:00, 708.17it/s]                                                                                                \n",
      "                                                                                                                                                              \r"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "from ela import generator\n",
    "\n",
    "import utils\n",
    "import metrics\n",
    "import datasets\n",
    "\n",
    "\n",
    "experiments = [\n",
    "    'nopoolrefinenet_dpn92_dual_hypercolumn_poly_lr_aux_data_pseudo_labels',\n",
    "]\n",
    "\n",
    "test_predictions_experiment = []\n",
    "\n",
    "for name in experiments:\n",
    "    test_predictions = utils.TestPredictions('{}'.format(name), mode='val')\n",
    "    test_predictions_experiment.append(test_predictions.load_raw())\n",
    "\n",
    "samples_train = utils.get_train_samples()\n",
    "transforms = generator.TransformationsGenerator([])\n",
    "dataset = datasets.AnalysisDataset(samples_train, './data/train', transforms, utils.TestPredictions('{}'.format(name), mode='val').load())\n",
    "\n",
    "train = {}\n",
    "for id in tqdm(samples_train):\n",
    "    _, mask, _ = dataset.get_by_id(id)\n",
    "    test_prediction = np.concatenate([predictions[id] for predictions in test_predictions_experiment], axis=0)\n",
    "    prediction = torch.mean(torch.sigmoid(torch.FloatTensor(test_prediction)), dim=0)\n",
    "    mask = torch.FloatTensor(mask)\n",
    "\n",
    "    train[id] = (prediction, mask)\n",
    "\n",
    "\n",
    "def strip_nan(e):\n",
    "    if e != e:\n",
    "        return None\n",
    "\n",
    "    return e[:-4]\n",
    "\n",
    "\n",
    "with open('./data/8_neighbours_mosaics.pkl', \"rb\") as f:\n",
    "    neighbors = pickle.load(f)\n",
    "    neighbors = {k[:-4]: [strip_nan(e) for e in v] for k, v in neighbors.items()}\n",
    "\n",
    "samples_test = utils.get_test_samples()\n",
    "masks_test = utils.TestPredictions('{}-split_{}'.format(name, 0)).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [00:08<00:00, 472.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP tensor(0.8736, device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "id_dataset = datasets.IdDataset(samples_train, './data/train')\n",
    "\n",
    "def get_mask(id):\n",
    "    if id in samples_train:\n",
    "        mask_n = id_dataset[id]\n",
    "\n",
    "    if id in samples_test:\n",
    "        mask_n = torch.FloatTensor(masks_test[id])\n",
    "        \n",
    "    return mask_n\n",
    "\n",
    "train_postprocessed = {id: (prediction.clone(), mask.clone()) for id, (prediction, mask) in train.items()}\n",
    "for sample in tqdm(samples_train):\n",
    "    if sample in neighbors:\n",
    "        sample_neighbors = neighbors[sample]\n",
    "        prediction_sample, mask_sample = train_postprocessed[sample]\n",
    "        \n",
    "        n_top, n_left, n_right, n_bottom =  sample_neighbors[1],  sample_neighbors[3],  sample_neighbors[4],  sample_neighbors[6]\n",
    "        if n_top and n_left and n_right and n_bottom:\n",
    "            top = get_mask(n_top)\n",
    "            left = get_mask(n_left)\n",
    "            right = get_mask(n_right)\n",
    "            bottom = get_mask(n_bottom)\n",
    "            \n",
    "            if torch.mean(top) > 0.7 and torch.mean(left) > 0.7 and torch.mean(right) > 0.7 and torch.mean(bottom) > 0.7:\n",
    "                prediction_sample[:, :] = 1\n",
    "                train_postprocessed[sample] = prediction_sample, mask_sample\n",
    "            \n",
    "            #print(torch.mean(prediction_sample), torch.mean(top), torch.mean(left), torch.mean(right), torch.mean(bottom))\n",
    "        \n",
    "        masks_neighbors = []\n",
    "        for n in sample_neighbors:\n",
    "            if n in samples_train:\n",
    "                mask_n = train[n][0]\n",
    "\n",
    "            if n in samples_test:\n",
    "                mask_n = torch.FloatTensor(masks_test[n])\n",
    "\n",
    "            masks_neighbors.append(mask_n)\n",
    "\n",
    "        if len(masks_neighbors) == 0:\n",
    "            continue\n",
    "\n",
    "        num_neighbors = len(masks_neighbors)\n",
    "        masks_neighbors = torch.cat(masks_neighbors, dim=0)\n",
    "        mean_neighbors = torch.mean(masks_neighbors)\n",
    "\n",
    "\n",
    "\n",
    "predictions = [prediction for id, (prediction, mask) in train_postprocessed.items()]\n",
    "predictions = torch.stack(predictions, dim=0).cuda(1)\n",
    "masks = [mask for id, (prediction, mask) in train_postprocessed.items()]\n",
    "masks = torch.stack(masks, dim=0).cuda(1)\n",
    "\n",
    "predictions = (predictions > 0.5).float()\n",
    "\n",
    "map = metrics.mAP(predictions, masks)\n",
    "\n",
    "print('mAP', map)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:KaggleSalt]",
   "language": "python",
   "name": "conda-env-KaggleSalt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
